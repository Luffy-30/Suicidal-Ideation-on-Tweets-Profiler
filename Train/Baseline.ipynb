{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-plot\n",
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "import time\n",
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "import gensim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from sklearn.metrics import classification_report,confusion_matrix,balanced_accuracy_score\n",
        "import scikitplot as skplt\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models import Word2Vec\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas(desc=\"progress-bar\")\n",
        "from gensim.models import doc2vec\n",
        "from sklearn import utils\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "\n"
      ],
      "metadata": {
        "id": "lbgQ1IMFWy0E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a723308c-4a6d-477e-91b1-8d347e1c3e5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-plot in /usr/local/lib/python3.8/dist-packages (0.3.7)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.8/dist-packages (from scikit-plot) (1.2.0)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.8/dist-packages (from scikit-plot) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.8/dist-packages (from scikit-plot) (1.0.2)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from scikit-plot) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.0.9)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.21.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_ds=\"/content/drive/MyDrive/FINAL/final.csv\"\n",
        "df=pd.read_csv(final_ds,encoding='utf-8',sep=',')\n",
        "\n",
        "df=df.dropna()\n",
        "df.head(15)\n",
        "df"
      ],
      "metadata": {
        "id": "8PBUP5QYWUDW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "c0197775-861a-4dcf-9553-7faa36cdda2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Created_at  \\\n",
              "0     2023-01-07 23:43:44+00:00   \n",
              "1     2023-01-08 02:44:02+00:00   \n",
              "2     2023-01-08 02:42:45+00:00   \n",
              "3     2023-01-08 02:41:31+00:00   \n",
              "4     2023-01-08 02:41:08+00:00   \n",
              "...                         ...   \n",
              "5951  2023-01-04 06:58:26+00:00   \n",
              "5952  2023-01-04 06:48:39+00:00   \n",
              "5953  2023-01-04 06:26:42+00:00   \n",
              "5954  2023-01-04 06:09:54+00:00   \n",
              "5955  2023-01-04 06:05:11+00:00   \n",
              "\n",
              "                                                  Tweet  Retweet_count  \\\n",
              "0                hotspurs at the top of my suicide note              0   \n",
              "1                     why is he wearing a chrome hoodie              0   \n",
              "2     me sharing my favorite songs on my IG stories ...           3970   \n",
              "3                                        man beat death              0   \n",
              "4      i have never seen your opps come back gracefu...              0   \n",
              "...                                                 ...            ...   \n",
              "5951                         idk if i can finish it man              0   \n",
              "5952  HOW COULD I BE AROUND DAISY JONES AND NOT BE M...              0   \n",
              "5953               my mother makes my blood boil yippee              0   \n",
              "5954  that was horrendousi almost threw up that was ...              0   \n",
              "5955  I sta ed replaying it with a speedhack and ins...              0   \n",
              "\n",
              "      Favourite_count      User  Followers           Location  Si  \n",
              "0                   0  1kayfiji        228  aka astra/ lotus    1  \n",
              "1                   1  1kayfiji        228  aka astra/ lotus    0  \n",
              "2                   0  1kayfiji        228  aka astra/ lotus    0  \n",
              "3                   0  1kayfiji        228  aka astra/ lotus    1  \n",
              "4                   1  1kayfiji        228  aka astra/ lotus    0  \n",
              "...               ...       ...        ...                ...  ..  \n",
              "5951                0    zoprys         19         Multiverse   0  \n",
              "5952                0    zoprys         19         Multiverse   0  \n",
              "5953                1    zoprys         19         Multiverse   0  \n",
              "5954                1    zoprys         19         Multiverse   0  \n",
              "5955                0    zoprys         19         Multiverse   0  \n",
              "\n",
              "[5955 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1d8641d-7097-43ef-80e9-7e9882a34f03\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Created_at</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Retweet_count</th>\n",
              "      <th>Favourite_count</th>\n",
              "      <th>User</th>\n",
              "      <th>Followers</th>\n",
              "      <th>Location</th>\n",
              "      <th>Si</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-01-07 23:43:44+00:00</td>\n",
              "      <td>hotspurs at the top of my suicide note</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1kayfiji</td>\n",
              "      <td>228</td>\n",
              "      <td>aka astra/ lotus</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023-01-08 02:44:02+00:00</td>\n",
              "      <td>why is he wearing a chrome hoodie</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1kayfiji</td>\n",
              "      <td>228</td>\n",
              "      <td>aka astra/ lotus</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023-01-08 02:42:45+00:00</td>\n",
              "      <td>me sharing my favorite songs on my IG stories ...</td>\n",
              "      <td>3970</td>\n",
              "      <td>0</td>\n",
              "      <td>1kayfiji</td>\n",
              "      <td>228</td>\n",
              "      <td>aka astra/ lotus</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023-01-08 02:41:31+00:00</td>\n",
              "      <td>man beat death</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1kayfiji</td>\n",
              "      <td>228</td>\n",
              "      <td>aka astra/ lotus</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2023-01-08 02:41:08+00:00</td>\n",
              "      <td>i have never seen your opps come back gracefu...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1kayfiji</td>\n",
              "      <td>228</td>\n",
              "      <td>aka astra/ lotus</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5951</th>\n",
              "      <td>2023-01-04 06:58:26+00:00</td>\n",
              "      <td>idk if i can finish it man</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>zoprys</td>\n",
              "      <td>19</td>\n",
              "      <td>Multiverse</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5952</th>\n",
              "      <td>2023-01-04 06:48:39+00:00</td>\n",
              "      <td>HOW COULD I BE AROUND DAISY JONES AND NOT BE M...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>zoprys</td>\n",
              "      <td>19</td>\n",
              "      <td>Multiverse</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5953</th>\n",
              "      <td>2023-01-04 06:26:42+00:00</td>\n",
              "      <td>my mother makes my blood boil yippee</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>zoprys</td>\n",
              "      <td>19</td>\n",
              "      <td>Multiverse</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5954</th>\n",
              "      <td>2023-01-04 06:09:54+00:00</td>\n",
              "      <td>that was horrendousi almost threw up that was ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>zoprys</td>\n",
              "      <td>19</td>\n",
              "      <td>Multiverse</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5955</th>\n",
              "      <td>2023-01-04 06:05:11+00:00</td>\n",
              "      <td>I sta ed replaying it with a speedhack and ins...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>zoprys</td>\n",
              "      <td>19</td>\n",
              "      <td>Multiverse</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5955 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1d8641d-7097-43ef-80e9-7e9882a34f03')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e1d8641d-7097-43ef-80e9-7e9882a34f03 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e1d8641d-7097-43ef-80e9-7e9882a34f03');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fianal_ds=\"/content/drive/MyDrive/FINAL/twitter-suicidal_data.csv\"\n",
        "daf=pd.read_csv(fianal_ds,encoding='utf-8',sep=',')\n",
        "\n",
        "daf=daf.dropna()\n",
        "daf.head(15)\n",
        "daf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "BrOTCxzRDGNs",
        "outputId": "691f7a34-767f-46c5-fa5c-19e5864bf8d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  tweet  intention\n",
              "0     my life is meaningless i just want to end my l...          1\n",
              "1     muttering i wanna die to myself daily for a fe...          1\n",
              "2     work slave i really feel like my only purpose ...          1\n",
              "3     i did something on the 2 of october i overdose...          1\n",
              "4     i feel like no one cares i just want to die ma...          1\n",
              "...                                                 ...        ...\n",
              "9114  have you ever laid on your bed at night and cr...          1\n",
              "9115  the fault the blame the pain s still there i m...          1\n",
              "9116  stop asking me to trust you when i m still cou...          1\n",
              "9117  i never know how to handle sadness crying make...          1\n",
              "9118  when cancer takes a life we blame cancer depre...          1\n",
              "\n",
              "[9119 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb0fa635-81f9-4e6b-be01-08b87aafcc09\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>intention</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>my life is meaningless i just want to end my l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>muttering i wanna die to myself daily for a fe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>work slave i really feel like my only purpose ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i did something on the 2 of october i overdose...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i feel like no one cares i just want to die ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9114</th>\n",
              "      <td>have you ever laid on your bed at night and cr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9115</th>\n",
              "      <td>the fault the blame the pain s still there i m...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9116</th>\n",
              "      <td>stop asking me to trust you when i m still cou...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9117</th>\n",
              "      <td>i never know how to handle sadness crying make...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9118</th>\n",
              "      <td>when cancer takes a life we blame cancer depre...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9119 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb0fa635-81f9-4e6b-be01-08b87aafcc09')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb0fa635-81f9-4e6b-be01-08b87aafcc09 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb0fa635-81f9-4e6b-be01-08b87aafcc09');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testx=df['Tweet'].values.astype('U')\n",
        "testy=df['Si'].values.astype('U')\n",
        "\n",
        "unique, counts = np.unique(testy, return_counts=True)\n",
        "unique,counts"
      ],
      "metadata": {
        "id": "1OzAwahOWUGb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50b58745-fc9b-4607-ee07-8f01a7efebdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['0', '1'], dtype='<U21'), array([5541,  414]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainx=daf['tweet'].values.astype('U')\n",
        "trainy=daf['intention'].values.astype('U')\n",
        "\n",
        "unique, counts = np.unique(trainy, return_counts=True)\n",
        "unique,counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ISRsy4tDuUB",
        "outputId": "92d750bf-25a4-48ea-f9bc-83816d312c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['0', '1'], dtype='<U21'), array([5121, 3998]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state = 42)"
      ],
      "metadata": {
        "id": "YxzAa1wkWUJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(trainy, return_counts=True)\n",
        "unique,counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUW4y8W2NXaM",
        "outputId": "96683d23-2917-4f12-ab4f-b6a8efc00553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['0', '1'], dtype='<U21'), array([5121, 3998]))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes Classifier**"
      ],
      "metadata": {
        "id": "EQwsBr25ez9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "nb = Pipeline([('vect', CountVectorizer()),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', MultinomialNB(alpha=1.0e-7)),\n",
        "              ])\n",
        "nb.fit(testx,testy)\n",
        "\n",
        "my_tags=['0','1']\n",
        "\n",
        "y_pred = nb.predict(trainx)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(trainy,y_pred))\n",
        "print(classification_report(trainy, y_pred,target_names=my_tags))\n",
        "d=y_pred.tolist()\n",
        "tr=pd.DataFrame(d)\n",
        "tr.value_counts()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rga2MGlpWUOz",
        "outputId": "5fcd693a-15ef-46dc-ab95-052800640bd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.546660818072157\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.96      0.70      5121\n",
            "           1       0.26      0.02      0.03      3998\n",
            "\n",
            "    accuracy                           0.55      9119\n",
            "   macro avg       0.41      0.49      0.37      9119\n",
            "weighted avg       0.43      0.55      0.41      9119\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    8835\n",
              "1     284\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression**\\\n",
        "Poor performance due to unbalanaced dataset"
      ],
      "metadata": {
        "id": "tJmsI_XMey2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
        "               ])\n",
        "logreg.fit(trainx, trainy)\n",
        "\n",
        "\n",
        "y_pred = logreg.predict(testx)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(testy,y_pred))\n",
        "print(classification_report(testy, y_pred))\n",
        "d=y_pred.tolist()\n",
        "tr=pd.DataFrame(d)\n",
        "tr.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dX5FeGUWURY",
        "outputId": "908bf9ee-c266-45b1-f176-12ca8cab30ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.8767422334172964\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.92      0.93      5541\n",
            "           1       0.24      0.36      0.29       414\n",
            "\n",
            "    accuracy                           0.88      5955\n",
            "   macro avg       0.60      0.64      0.61      5955\n",
            "weighted avg       0.90      0.88      0.89      5955\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    5335\n",
              "1     620\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SGD Classifier**"
      ],
      "metadata": {
        "id": "34PD_GSOhjPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-8, random_state=42, max_iter=5, tol=None)),\n",
        "               ])\n",
        "sgd.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "y_pred = sgd.predict(X_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_test,y_pred))\n",
        "print(classification_report(y_test, y_pred,target_names=my_tags))\n",
        "\n",
        "d=y_pred.tolist()\n",
        "tr=pd.DataFrame(d)\n",
        "tr.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvsfgSVS3rNs",
        "outputId": "eb76da53-ba2b-4444-c8d3-20a72da917c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.9038623005877414\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.95      2210\n",
            "           1       0.35      0.40      0.37       172\n",
            "\n",
            "    accuracy                           0.90      2382\n",
            "   macro avg       0.65      0.67      0.66      2382\n",
            "weighted avg       0.91      0.90      0.91      2382\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2189\n",
              "1     193\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word2vec embeddings**"
      ],
      "metadata": {
        "id": "sTDbgMqxkahL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def w2v_tokenize_text(text):\n",
        "    tokens = []\n",
        "    for sent in nltk.sent_tokenize(text, language='english'):\n",
        "        for word in nltk.word_tokenize(sent, language='english'):\n",
        "            if len(word) < 2:\n",
        "                continue\n",
        "            tokens.append(word)\n",
        "    return tokens\n"
      ],
      "metadata": {
        "id": "ehh7cwf731cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_sentences(corpus, label_type):\n",
        "\n",
        "    labeled = []\n",
        "    for i, v in enumerate(corpus):\n",
        "        label = label_type + '_' + str(i)\n",
        "        labeled.append(doc2vec.TaggedDocument(v.split(), [label]))\n",
        "    #print(labeled)\n",
        "    return labeled\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.Tweet, df.Si, random_state=0, test_size=0.3)\n",
        "\n",
        "X_train = label_sentences(X_train, 'Train')\n",
        "X_test = label_sentences(X_test, 'Test')\n",
        "all_data = X_train + X_test"
      ],
      "metadata": {
        "id": "ZhwBGChl_YFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_test, return_counts=True)\n",
        "unique,counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2QRnxDymePa",
        "outputId": "59cc6261-0561-4e45-be63-1cc29f8eb357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([1679,  108]))"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dbow = Doc2Vec(dm=0, vector_size=200, negative=5, min_count=1, alpha=0.075, min_alpha=0.050)\n",
        "model_dbow.build_vocab([x for x in tqdm(all_data)])\n",
        "\n",
        "for epoch in range(30):\n",
        "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n",
        "    model_dbow.alpha -= 0.0001\n",
        "    model_dbow.min_alpha = model_dbow.alpha"
      ],
      "metadata": {
        "id": "rF6mib5lAA3y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "318582d8-7e4f-47b3-df0b-52fc7ab02912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5955/5955 [00:00<00:00, 1434722.29it/s]\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 1571775.24it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 2792295.17it/s]\n",
            "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 1846051.76it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 2596909.99it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 3414501.75it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 1371086.37it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 1777601.62it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 2018186.84it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 2530862.33it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 1693246.58it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 1428567.85it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 1784714.56it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 1595775.64it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 2376732.36it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 1410576.63it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 1646804.27it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 3356232.24it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 905032.26it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 1833987.83it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 1845915.33it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 1373121.51it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 1708886.17it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 1719947.69it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 3195225.83it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 1898242.92it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 1906501.82it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 1584739.57it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 1339469.10it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 2070552.96it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100%|██████████| 5955/5955 [00:00<00:00, 1885204.95it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
        "\n",
        "    vectors = np.zeros((corpus_size, vectors_size))\n",
        "    for i in range(0, corpus_size):\n",
        "        prefix = vectors_type + '_' + str(i)\n",
        "        vectors[i] = model.docvecs[prefix]\n",
        "    return vectors\n",
        "\n",
        "train_vectors_dbow = get_vectors(model_dbow, len(X_train), 200, 'Train')\n",
        "test_vectors_dbow = get_vectors(model_dbow, len(X_test), 200, 'Test')"
      ],
      "metadata": {
        "id": "gh4SplgvBOjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression**"
      ],
      "metadata": {
        "id": "56YG63aclfm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
        "logreg.fit(train_vectors_dbow, y_train)\n",
        "logreg = logreg.fit(train_vectors_dbow, y_train)\n",
        "y_pred = logreg.predict(test_vectors_dbow)\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred))\n",
        "d=y_pred.tolist()\n",
        "tr=pd.DataFrame(d)\n",
        "tr.value_counts()"
      ],
      "metadata": {
        "id": "TW5Y94ROCj6S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd298bfb-f2c9-4abb-eb96-e6ec6ff526e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.9306099608282037\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96      1679\n",
            "           1       0.35      0.18      0.23       108\n",
            "\n",
            "    accuracy                           0.93      1787\n",
            "   macro avg       0.65      0.58      0.60      1787\n",
            "weighted avg       0.91      0.93      0.92      1787\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1733\n",
              "1      54\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree Classifier**"
      ],
      "metadata": {
        "id": "XJft6Yy3lqEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dtc = DecisionTreeClassifier(class_weight='balanced')\n",
        "label=['0','1']\n",
        "print('Results for DecisionTree Classifier:-\\n')\n",
        "start_time = time.time()\n",
        "dtc.fit(train_vectors_dbow,y_train)\n",
        "dtc_time = (time.time() - start_time)\n",
        "print('*'*80)\n",
        "print('\\nTraining time(sec) = ',dtc_time)\n",
        "\n",
        "y_pred1 = dtc.predict(train_vectors_dbow)\n",
        "\n",
        "start_time = time.time()\n",
        "y_pred = dtc.predict(test_vectors_dbow)\n",
        "dtc_time2 = (time.time() - start_time)\n",
        "print('Prediction time(sec) = ',dtc_time2)\n",
        "cm_dtc = confusion_matrix(y_test, y_pred)\n",
        "dtc_miss = np.sum(y_pred!=y_test)\n",
        "acc1_dtc = balanced_accuracy_score(y_train,y_pred1)\n",
        "acc2_dtc = balanced_accuracy_score(y_test,y_pred)\n",
        "print('\\n')\n",
        "print('*'*80)\n",
        "\n",
        "print('\\nTraining score = ',acc1_dtc)\n",
        "print('Testing score = ',acc2_dtc)\n",
        "print('\\n')\n",
        "print('*'*80)\n",
        "\n",
        "print('\\n')\n",
        "for i in range(len(np.unique(y_train))):\n",
        "    err = np.sum(cm_dtc[i])-cm_dtc[i][i]\n",
        "    print('No of missclassified for class {} (test data) = {} '.format(label[i],err))\n",
        "print('-'*65)\n",
        "print('Total no of missclassified points (test data) = ',dtc_miss)\n",
        "print('Total % of missclassified points (test data) = ',(dtc_miss/len(y_test))*100)\n",
        "print('\\n')\n",
        "print('*'*80)\n",
        "\n",
        "print('\\n\\nConfusion matrix:')\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred)\n",
        "plt.show()\n",
        "print('\\n')\n",
        "print('*'*80)\n",
        "\n",
        "print('\\n\\nClassification report:-\\n')\n",
        "print(classification_report(y_test,y_pred))\n",
        "print('\\n')\n",
        "print('*'*80)\n",
        "\n",
        "DTC = [acc1_dtc, acc2_dtc, dtc_miss, dtc_miss/len(y_test), dtc_time, dtc_time2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q6HBTAmgB_WH",
        "outputId": "cef3a88d-7c3d-4d64-d8ce-a56c3118eaa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for DecisionTree Classifier:-\n",
            "\n",
            "********************************************************************************\n",
            "\n",
            "Training time(sec) =  0.7029409408569336\n",
            "Prediction time(sec) =  0.0011706352233886719\n",
            "\n",
            "\n",
            "********************************************************************************\n",
            "\n",
            "Training score =  1.0\n",
            "Testing score =  0.6088114618489842\n",
            "\n",
            "\n",
            "********************************************************************************\n",
            "\n",
            "\n",
            "No of missclassified for class 0 (test data) = 101 \n",
            "No of missclassified for class 1 (test data) = 78 \n",
            "-----------------------------------------------------------------\n",
            "Total no of missclassified points (test data) =  179\n",
            "Total % of missclassified points (test data) =  10.016787912702855\n",
            "\n",
            "\n",
            "********************************************************************************\n",
            "\n",
            "\n",
            "Confusion matrix:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "********************************************************************************\n",
            "\n",
            "\n",
            "Classification report:-\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.95      1679\n",
            "           1       0.23      0.28      0.25       108\n",
            "\n",
            "    accuracy                           0.90      1787\n",
            "   macro avg       0.59      0.61      0.60      1787\n",
            "weighted avg       0.91      0.90      0.90      1787\n",
            "\n",
            "\n",
            "\n",
            "********************************************************************************\n"
          ]
        }
      ]
    }
  ]
}